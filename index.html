  <!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="description" content=" - Zhouhan's responsive personal homepage">
  <!-- meta name="keywords" content="Martin Luther, resume, cv, portfolio, personal, developer, designer, onepage, clean, modern, velocity, web" -->
  <meta name="author" content="Zhouhan Lin">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <title>Zhouhan Lin - Homepage </title>
  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="milaico.ico">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Poppins:300,300i,400,400i,500,500i,600,600i,700,700i,800,800i" rel="stylesheet">

  <!-- End -->

  <!-- Plugin Css -->
  <link href="static/plugin/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="static/plugin/font-awesome/css/font-awesome.min.css" rel="stylesheet">
  <link href="static/plugin/owl-carousel/css/owl.carousel.min.css" rel="stylesheet">
  <!-- End -->

  <!-- Theme css -->
  <link href="static/css/style.css" rel="stylesheet">
  <link href="static/css/color/blue.css" rel="stylesheet">
  <!-- End -->

  <!--[if lt IE 9]>
    <script src="static/js/html5shiv.min.js"></script>
    <script src="static/js/respond.min.js"></script>
  <![endif]-->
</head>

<!-- ========== Body Starts ========== -->
<body>
  <div id="loading">
    <div class="load-circle"><span class="one"></span></div>
  </div>

  <!-- ========== Header Starts ========== -->
  <header class="header">
    <nav class="navbar">
      <div class="container">
        <div class="navbar-header">
          <!-- Mobile Toggle -->
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <!-- / Mobile Toggle -->

          <!-- Logo  -->
          <h1 class="logo">
            <a href="#">Zhouhan Lin</a>
          </h1>
          <!-- / Logo  -->
        </div>
        <!-- Navbar -->
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav navbar-right">
            <li class="current"><a href="#home">Home</a></li>
            <li><a href="#research">Research</a></li>
            <li><a href="#backgrounds">Education</a></li>
            <li><a href="#backgrounds">Internships</a></li>
            <li><a href="#services">Services</a></li>
            <li><a href="#awards">Awards</a></li>
            <li><a href="#awards">Media</a></li>
            <!-- li><a href="#miscellaneous">Miscellaneous</a></li -->
          </ul>
        </div>
        <!-- / Navbar -->
      </div>
    </nav>
  </header>
  <!-- ========== End Of Header ========== -->

  <!-- ========== Particle Home ==========
  <section id="home" class="particles-box full-screen bg-cover bg-no-repeat"
      style="background-image: url(static/img/1600x1000.jpg);" >
      <div class="container">
        <div class="banner-center-text">
          <h1 style="text-align:center;">Zhouhan Lin (林洲汉)</h1>
          <p style="text-align:center;">Ph.D. student in Machine Learning and Natural Language Processing</p>
        </div>
      </div>
    </section>
  ========== End Of Particle Home ========== -->
  <!-- ========== Home ========== -->
  <section id="home" class="section skills-box" data-parallax="scroll">
    <div class="container"> 
      <div class="welcome-text">
        <div class="about-me-box">
          <div class="row">
            <div class="col-md-5">
              <div class="avtar">
                <img src="static/img/coverphoto.jpg">
              </div>
            </div>
            <div class="col-md-1"> </div>
            <div class="col-md-6">
              <h3>Zhouhan Lin (林洲汉)</h3>
              <ul class="about-me">
                <li><strong>E-mail : </strong>lastname[dot]firstname[at]gmail.com</li>
                <li><strong>Phone : </strong>650-788-4556</li>
              </ul>
          <p>Hello! I'm Zhouhan Lin, a visiting scientist at Facebook AI Research. 
          In 2021, I am going to join Shanghai Jiaotong University as an assistant professor.
          I graduated from the Mila lab in the University of Montreal, where I have
          the honor to be supervised by Yoshua Bengio.
          <br> 
          My research interests include machine learning and natural language
          processing, especially in attention mechanisms and its applications,
          language modeling, question answering, syntactic parsing, and binary
          networks.
          </p>
          <!-- <strong>Hello! i'm Martin Luther</strong> -->
              <div class="about-actions">
                <button class="m-btn-01 lets-talk">contact me <i class="fa fa-arrow-right"></i></button>
                <button class="m-btn-01"><a href="static/files/CV_Zhouhan_Lin.pdf">download cv</a> <i class="fa fa-arrow-right"></i></button>
              </div>
              <div class="social-link">
                  <ul>
                    <li><a href="#"><i class="fa fa-facebook" aria-hidden="true"></i></a></li>
                    <li><a href="#"><i class="fa fa-twitter" aria-hidden="true"></i></a></li>
                    <li><a href="#"><i class="fa fa-linkedin" aria-hidden="true"></i></a></li>
                    <!-- li><a href="https://www.zhihu.com/people/linzhouhan">
                        <span class="fa-stack fa-lg">
                          <i class="fa fa-stack-2x fa-circle"></i>
                          <i class="fa fa-stack-1x fa-inverse">知</i>
                        </span>
                        </a>
                    </li -->
                  </ul>
              </div><!-- .social-link -->
            </div>
          </div><!-- .Row -->
        </div> <!-- about me -->
      </div>
    </div>
  </section>
  <!-- ========== End Of Home ========== -->


  <!-- ========== Research ========== -->
  <section id="research" class="section grey-bg"> 
    <div class="container">

      <div class="section-title-01">
        <h2>Selected Publications</h2>
      </div><!-- .section-title -->
      
      <div class="section-title-01">
        <p>Please visit my <a href="https://scholar.google.ca/citations?user=LNZ4efwAAAAJ&hl=en">Google Scholar</a> page for a full list of my publications.</p>
      </div><!-- .section-title -->

      <div class="paper-box">
        <div class="row">
          <div class="col-md-4">
            <div class="avtar">
              <img src="static/img/distanceparser.png">
            </div>
          </div>
          <div class="col-md-8">
            <h2>Straight to the Tree: Constituency Parsing with Neural Syntactic Distance</h2>
            <h3>Yikang Shen*, Zhouhan Lin*, Athul Paul Jacob, Alessandro Sordoni, Aaron Courville, Yoshua Bengio</h3>
            <p> ACL 2018 | 
                <a href="http://aclweb.org/anthology/P18-1108">pdf</a> |
                <a href="">slides</a> | 
                <a href="">codes</a> </p>
            <p>We propose a novel constituency parsing scheme. The model
            predicts a vector of real-valued scalars, named syntactic
            distances, for each split position in the input sentence. The
            syntactic distances specify the order in which the split points
            will be selected, recursively partitioning the input, in a top-down
            fashion. Compared to traditional shiftreduce parsing schemes, our
            approach is free from the potential problem of compounding errors,
            while being faster and easier to parallelize. Our model achieves
            competitive performance amongst single model, discriminative
            parsers in the PTB dataset and outperforms previous models in the
            CTB dataset.</p>
          </div>
        </div><!-- .Row -->
      </div> <!-- paper-box -->
      
      <div class="paper-box">
        <div class="row">
          <div class="col-md-4">
            <div class="avtar">
              <img src="static/img/rrnn.png">
            </div>
          </div>
          <div class="col-md-8">
            <h2>Learning Hierarchical Structures On-The-Fly with a Recurrent-Recursive Model for Sequences</h2>
            <h3>Athul Paul Jacob*, Zhouhan Lin*, Alessandro Sordoni, Yoshua Bengio </h3>
            <p> ACL 2018 workshop | 
                <a href="http://aclweb.org/anthology/W18-3020">pdf</a> |
                <a href="">poster</a> </p>
            <p>We propose a hierarchical model for sequential data that learns
            a tree on-the-fly, i.e. while reading the sequence. In the model, a
            recurrent network adapts its structure and reuses recurrent weights
            in a recursive manner. This creates adaptive skip-connections that
            ease the learning of long-term dependencies. The tree structure can
            either be inferred without supervision through reinforcement
            learning, or learned in a supervised manner. We provide preliminary
            experiments in a novel Math Expression Evaluation (MEE) task, which
            is explicitly crafted to have a hierarchical tree structure that
            can be used to study the effectiveness of our model. Additionally,
            we test our model in a wellknown propositional logic and language
            modelling tasks. Experimental results show the potential of our
            approach.  </p>
          </div>
        </div><!-- .Row -->
      </div> <!-- paper-box -->
      
      <div class="paper-box">
        <div class="row">
          <div class="col-md-4">
            <div class="avtar">
              <img src="static/img/tree.png">
            </div>
          </div>
          <div class="col-md-8">
            <h2>Neural Language Modeling by Jointly Learning Syntax and Lexicon </h2>
            <h3>Yikang Shen, Zhouhan Lin, Chin-Wei Huang, Aaron Courville </h3>
            <p> ICLR 2018 | 
                <a href="https://arxiv.org/pdf/1510.03009.pdf">pdf</a> |
                <a href="">slides</a> |
                <a href="">codes</a> |
                <a href="">poster</a> </p>
            <p>We propose a neural language model capable of unsupervised
            syntactic structure induction. The model leverages the structure
            information to form better semantic representations and better
            language modeling. Standard recurrent neural networks are limited
            by their structure and fail to efficiently use syntactic
            information. On the other hand, tree-structured recursive networks
            usually require additional structural supervision at the cost of
            human expert annotation. In this paper, We propose a novel neural
            language model, called the Parsing-Reading-Predict Networks (PRPN),
            that can simultaneously induce the syntactic structure from
            unannotated sentences and leverage the inferred structure to learn
            a better language model. In our model, the gradient can be directly
            back-propagated from the language model loss into the neural
            parsing network. Experiments show that the proposed model can
            discover the underlying syntactic structure and achieve
            state-of-the-art performance on word/character-level language model
            tasks.  </p>
          </div>
        </div><!-- .Row -->
      </div> <!-- paper-box -->
    
      <div class="paper-box">
        <div class="row">
          <div class="col-md-4">
            <div class="avtar">
              <img src="static/img/semlp.png">
            </div>
          </div>
          <div class="col-md-8">
            <h2>A structured self-attentive Sentence Embedding</h2>
            <h3>Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou and Yoshua Bengio </h3>
            <p> ICLR 2017 | 
                <a href="https://arxiv.org/pdf/1703.03130.pdf">pdf</a> |
                <a href="">slides</a> |
                <a href="">codes</a> |
                <a href="">poster</a> </p>
            <p>We propose a new model for extracting an interpretable sentence
            embedding by introducing self-attention. Instead of using a vector,
            we use a 2-D matrix to represent the embedding, with each row of
            the matrix attending on a different part of the sentence. We also
            propose a self-attention mechanism and a special regularization
            term for the model. As a side effect, the embedding comes with an
            easy way of visualizing what specific parts of the sentence are
            encoded into the embedding. We evaluate our model on 3 different
            tasks: author profiling, sentiment classification, and textual
            entailment. Results show that our model yields a significant
            performance gain compared to other sentence embedding methods in
            all of the 3 tasks. </p>
          </div>
        </div><!-- .Row -->
      </div> <!-- paper-box -->
      
      <div class="paper-box">
        <div class="row">
          <div class="col-md-4">
            <div class="avtar">
              <img src="static/img/exp_quant.png">
            </div>
          </div>
          <div class="col-md-8">
            <h2>Neural networks with few multiplications</h2>
            <h3>Zhouhan Lin, Matthieu Courbariaux, Roland Memisevic, and Yoshua Bengio </h3>
            <p> ICLR 2016 | 
                <a href="https://arxiv.org/pdf/1510.03009.pdf">pdf</a> |
                <a href="">slides</a> |
                <a href="">codes</a> |
                <a href="">poster</a> </p>
            <p>For most deep learning algorithms training is notoriously time
            consuming. Since most of the computation in training neural
            networks is typically spent on floating point multiplications, we
            investigate an approach to training that eliminates the need for
            most of these. Our method consists of two parts: First we
            stochastically binarize weights to convert multiplications involved
            in computing hidden states to sign changes. Second, while
            back-propagating error derivatives, in addition to binarizing the
            weights, we quantize the representations at each layer to convert
            the remaining multiplications into binary shifts. Experimental
            results across 3 popular datasets (MNIST, CIFAR10, SVHN) show that
            this approach not only does not hurt classification performance but
            can result in even better performance than standard stochastic
            gradient descent training, paving the way to fast, hardwarefriendly
            training of neural networks.  </p>
          </div>
        </div><!-- .Row -->
      </div> <!-- paper-box -->
      
      <div class="paper-box">
        <div class="row">
          <div class="col-md-4">
            <div class="avtar">
              <img src="static/img/z_lin.png">
            </div>
          </div>
          <div class="col-md-8">
            <h2>How far can we go without convolution: Improving fully-connected networks </h2>
            <h3>Zhouhan Lin, Roland Memisevic, and Kishore Konda </h3>
            <p> ICLR 2016 workshop | 
                <a href="https://arxiv.org/pdf/1511.02580.pdf">pdf</a> |
                <a href="">slides</a> |
                <a href="">codes</a> |
                <a href="">poster</a> </p>
            <p>We propose ways to improve the performance of fully connected
            networks. We found that two approaches in particular have a strong
            effect on performance: linear bottleneck layers and unsupervised
            pre-training using autoencoders without hidden unit biases. We show
            how both approaches can be related to improving gradient flow and
            reducing sparsity in the network. We show that a fully connected
            network can yield approximately 70% classification accuracy on the
            permutationinvariant CIFAR-10 task, which is much higher than the
            current state-of-the-art.  By adding deformations to the training
            data, the fully connected network achieves 78% accuracy, which is
            just 10% short of a decent convolutional network.  </p>
          </div>
        </div><!-- .Row -->
      </div> <!-- paper-box -->
    
      <div class="paper-box">
        <div class="row">
          <div class="col-md-4">
            <div class="avtar">
              <img src="static/img/rnnternary.png">
            </div>
          </div>
          <div class="col-md-8">
            <h2>Recurrent Neural Networks with Limited Numerical Precision </h2>
            <h3>Joachim Ott*, Zhouhan Lin*, Ying Zhang, Shih-Chii Liu, and Yoshua Bengio </h3>
            <p> NIPS 2016 workshop | 
                <a href="https://arxiv.org/pdf/1608.06902.pdf">pdf</a> |
                <a href="">slides</a> |
                <a href="">poster</a> </p>
            <p>Recurrent Neural Networks (RNNs) produce state-of-art
            performance on many machine learning tasks but their demand on
            resources in terms of memory and computational power are often
            high. Therefore, there is a great interest in optimizing the
            computations performed with these models especially when
            considering development of specialized low-power hardware for deep
            networks. One way of reducing the computational needs is to limit
            the numerical precision of the network weights and biases. This has
            led to different proposed rounding methods which have been applied
            so far to only Convolutional Neural Networks and Fully-Connected
            Networks.  This paper addresses the question of how to best reduce
            weight precision during training in the case of RNNs. We present
            results from the use of different stochastic and deterministic
            reduced precision training methods applied to three major RNN types
            which are then tested on several datasets. The results show that
            the weight binarization methods do not work with the RNNs.
            However, the stochastic and deterministic ternarization, and
            pow2-ternarization methods gave rise to low-precision RNNs that
            produce similar and even higher accuracy on certain datasets
            therefore providing a path towards training more efficient
            implementations of RNNs in specialized hardware.  </p>
          </div>
        </div><!-- .Row -->
      </div> <!-- paper-box -->
    
      <div class="paper-box">
        <div class="row">
          <div class="col-md-4">
            <div class="avtar">
              <img src="static/img/hsiclassify.png">
            </div>
          </div>
          <div class="col-md-8">
            <h2>Deep learning-based classification of hyperspectral data </h2>
            <h3>Yushi Chen, Zhouhan Lin, Xing Zhao, Gang Wang, and Yanfeng Gu </h3>
            <p> Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2014 | 
                <a href="">pdf</a> |
                <a href="">codes</a> </p>
            <p>Classification is one of the most popular topics in
            hyperspectral remote sensing. In the last two decades, a huge
            number of methods were proposed to deal with the hyperspectral data
            classification problem. However, most of them do not hierarchically
            extract deep features. In this paper, the concept of deep learning
            is introduced into hyperspectral data classification for the first
            time. First, we verify the eligibility of stacked autoencoders by
            following classical spectral information-based classification.
            Second, a new way of classifying with spatial-dominated information
            is proposed. We then propose a novel deep learning framework to
            merge the two features, from which we can get the highest
            classification accuracy. The framework is a hybrid of principle
            component analysis (PCA), deep learning architecture, and logistic
            regression. Specifically, as a deep learning architecture, stacked
            autoencoders are aimed to get useful high-level features.
            Experimental results with widely-used hyperspectral data indicate
            that classifiers built in this deep learning-based framework
            provide competitive performance. In addition, the proposed joint
            spectral–spatial deep neural network opens a new window for future
            research, showcasing the deep learning-based methods’ huge
            potential for accurate hyperspectral data classification.  </p>
          </div>
        </div><!-- .Row -->
      </div> <!-- paper-box -->
    
    </div><!-- .container -->
  </section>
  <!-- ========== End Of Research ========== -->

  <!-- ========== Resume  ========== -->
  <section id="backgrounds" class="section"> 
    <div class="container">
      <div class="section-title-01">
        <h2>Backgrounds</h2>
      </div><!-- .section-title -->

      <div class="row">
        <div class="col-sm-6 col-xs-12">
          <div class="resume-box-01">
            <h4><i class="fa fa-graduation-cap"></i> EDUCATION</h4>
            <div class="resume-row">
              <h5><i class="fa fa-graduation-cap"></i> Mila, University of Montreal</h5>
              <label>Ph.D. SEP 2014 - present</label>
              <p>Department of Computer Science and Operational Research</p>
              <p>Supervisor: Yoshua Bengio</p>
            </div><!-- .resume-row -->
            
            <div class="resume-row">
              <h5><i class="fa fa-graduation-cap"></i> Harbin Institute of Technology</h5>
              <label>M.Sc. AUG 2012 - JUL 2014</label>
              <p>Department of Electronics and Information Engineering</p>
              <p>Supervisor: Yushi Chen</p>
              <p>Honored Masters Graduate of HIT (2/36) </p>
              <p>Excellent Masters Thesis (2/36) </p>
            </div><!-- .resume-row -->

            <div class="resume-row">
              <h5><i class="fa fa-graduation-cap"></i> Harbin Institute of Technology</h5>
              <label>B.Sc. AUG 2008 - JUL 2012</label>
              <p>Department of Electronics and Information Engineering</p>
              <p>Honored Graduate of HIT (top 10%) </p>
              <p>Excellent Graduation Thesis (top 5%) </p>
            </div><!-- .resume-row -->
          </div><!-- .resume-box -->
        </div><!-- .col-sm-6 col-xs-12 -->

        <div class="col-sm-6 col-xs-12">
          <div class="resume-box-01">
            <h4><i class="fa fa-briefcase"></i> INTERNSHIPS</h4>
            <div class="resume-row">
              <h5><i class="fa fa-briefcase"></i> Google Inc., Montreal</h5>
              <label>OCT 2018 - DEC 2018</label>
              <p>Student Researcher </p>
            </div><!-- .resume-row -->
            
            <div class="resume-row">
              <h5><i class="fa fa-briefcase"></i> Google Inc., New York</h5>
              <label>JUN 2018 - SEP 2018</label>
              <p>Summer Intern </p>
            </div><!-- .resume-row -->
            
            <div class="resume-row">
              <h5><i class="fa fa-briefcase"></i> Microsoft Research, Montreal</h5>
              <label>SEP 2017 - MAY 2018</label>
              <p>Student Researcher </p>
            </div><!-- .resume-row -->
            
            <div class="resume-row">
              <h5><i class="fa fa-briefcase"></i> IBM Research, New York</h5>
              <label>JUN 2016 - OCT 2016</label>
              <p>Summer Intern </p>
            </div><!-- .resume-row -->
            
            <div class="resume-row">
              <h5><i class="fa fa-briefcase"></i> Chinese Academy of Sciences, Ningbo </h5>
              <label>FEB 2012</label>
              <p>Undergrad Intern </p>
            </div><!-- .resume-row -->

          </div><!-- .resume-box -->
        </div><!-- .col-sm-6 col-xs-12 -->

      </div><!-- .row -->
    </div><!-- .container -->
  </section>
  <!-- ========== End Of Resume ========== -->

  <!-- ========== Servicess  ========== -->
  <section id="services" class="section grey-bg">
    <div class="container">
      <div class="section-title-01">
        <h2>Professional Servicess</h2>
      </div><!-- .section-title -->
        <ul>
          <li> <strong> Conference Reviewer: </strong> NeurIPS (and former NIPS), ICML, ICLR, AAAI </li>
          <li> <strong> Journal Reviewer (in early years): </strong>
Canadian Journal of Remote Sensing;
Journal of Applied Remote Sensing;
IEEE TNNLS, TIP, TGARS, TOC, GRSM, JBHI; Applied Soft Computing
      <div class="row">
      </div><!-- .row -->
    </div><!-- .container -->
  </section>
  <!-- ========== End Of Services ========== -->

  <!-- ========== Awards  ========== -->
  <section id="awards" class="section">
    <div class="container">

      <div class="row">
        <div class="col-sm-6 col-xs-12">
          <div class="section-title-01">
            <h2>Awards</h2>
          </div><!-- .section-title -->
          <ul>
            <li> AdeptMind Scholarship, 2018 </li>
            <li> ICLR Travel Award, 2016, 2017, 2018 </li>
            <li> 2nd Place in NIPS Demonstration, 2017 </li>
            <li> Best workshop paper mention, NIPS 2016 </li>
            <li> First-class Scholarship, 2012, 2013 </li>
            <li> People’s Scholarship, 2011 </li>
            <li> Shinchang Corporation Scholarship, 2010 </li>
            <li> Freshman Foundation for Research and Innovation, 2008 </li>
          </ul>
        </div><!-- .col-sm-6 col-xs-12 -->

        <div class="col-sm-6 col-xs-12">
          <div class="section-title-01">
            <h2>Media Exposures</h2>
          </div><!-- .section-title -->
          <ul>
              <li> <a href="https://www. technologyreview.com/s/542366/ibm-making-plans-to-commercialize-its-brain-inspired-chip/">IBM Making Plans to Commercialize Its Brain-Inspired Chip</a>, MIT Tech Review </li>
              <li><a href="https://www.jiqizhixin.com/articles/100902">What is self-attention?</a>, Synced
          </ul>

        </div><!-- .col-sm-6 col-xs-12 -->
      </div><!-- .row -->
    </div><!-- .container -->
  </section>
  <!-- ========== End Of Awards ========== -->

  <!-- ========== Misc ==========
  <section id="miscellaneous" class="section grey-bg">
    <div class="container">
      <div class="section-title-01">
        <h2>Miscellaneous</h2>
      </div>

      <div class="row">
      </div>
    </div>
  </section>
  ========== End Of Misc ========== -->
  
  <!-- ========== Contact ========== -->
  <section id="contact" class="section contact-us-01 grey-bg"> 
    <div class="container">    
      <div class="section-title-01">
        <h2>Contact Me</h2>
      </div>

      <div class="row">
        <div class="col-sm-7 col-xs-12 col-md-7">
          <div class="contact-form-01">
          <form id="contact_form">
            <div class="row">
              <div class="col-md-6">
                <div class="form-group">
                  <label class="sr-only">Name</label>
                  <i class="fa fa-user" aria-hidden="true"></i>
                  <input class="form-control" name="name" placeholder="Name" type="text">
                </div>    
              </div><!-- .col-md-6 -->
              <div class="col-md-6">
                <div class="form-group">
                  <label class="sr-only">Email</label>
                  <i class="fa fa-envelope-o" aria-hidden="true"></i>
                  <input class="form-control" name="name" placeholder="Email" type="email">
                </div>    
              </div><!-- .col-md-6 -->
              <div class="col-md-12">
                <div class="form-group">
                  <label class="sr-only">Your message</label>
                  <textarea class="form-control" name="message" rows="7" placeholder="Your message"></textarea>
                </div>
              </div><!-- .col-md-12 -->
              <div class="col-md-12">
                <div class="action">
                  <button class="m-btn-01 lets-talk">Send Message <i class="fa fa-arrow-right"></i></button>
                </div>
              </div><!-- .col-md-12 -->
            </div><!-- .row -->
            
          </form>
          </div>
        </div><!-- .col-sm-8 col-xs-12 -->

        <div class="col-md-4 col-sm-6 col-xs-12">
          <ul class="contact-info-01">
            <li>
              <i class="fa fa-map-marker"></i>
              <h4>Adress:</h4>
              <p>Roomm. 3248, Pav. Andre-Aisenstadt,Universite de Montreal <br> 
                 Montreal, Quebec, Canada. H3T 1J4 </p>
            </li>
            <li>
              <i class="fa fa-envelope"></i>
              <h4>Email:</h4>
              <p>
                <a href="mailto:lin.zhouhan@gmail.com">lin.zhouhan@gmail.com</a>
              </p>
            </li>
          </ul><!-- .contact-info -->
        </div><!-- .col-sm-4 col-xs-12 -->
      </div><!-- .row -->
    </div><!-- .container -->
  </section>
  <!-- ========== End Of Contact ========== -->

  <!-- ========== Footer ========== -->
  <footer class="footer"> 
    <div class="main-footer text-center">
      <h4 class="footer-logo">ZHOUHAN LIN</h4>
      <div class="social-link">
        <ul>
          <li><a href="#"><i class="fa fa-facebook" aria-hidden="true"></i></a></li>
          <li><a href="#"><i class="fa fa-twitter" aria-hidden="true"></i></a></li>
          <li><a href="#"><i class="fa fa-linkedin" aria-hidden="true"></i></a></li>
        </ul>
      </div><!-- .social-link -->
    </div><!-- .main-footer -->
    <div class="sub-footer  text-center">
      <p>Copy Left <span class="copyleft">&copy;</span> By Zhouhan Lin 2016-18 </p>
    </div>
  </footer> <!-- .footer -->
  <!-- ========== End Of Footer ========== -->

  <!-- Jquery -->
  <script src="static/js/jquery.js"></script>
  <!-- End -->

  <!-- Plugin JS -->
  <script src="static/plugin/bootstrap/js/bootstrap.js"></script><!--bootstrap-->
  <script src="static/plugin/parallax/parallax.min.js"></script><!-- parallax library -->
  <script src="static/plugin/mixitup/mixitup.min.js"></script><!-- mixitup -->
  <script src="static/plugin/owl-carousel/js/owl.carousel.min.js"></script><!-- owl-carousel -->
  <script src="static/plugin/skills-bar/js/skill.bars.jquery.js"></script>
  <script src="static/plugin/skills-bar/js/skill.js"></script>
  <!-- skill.bars.jquery
  <script src="static/plugin/particles/particles.js"></script>
  <script src="static/plugin/particles/particles-app.js"></script>
  End -->

  <!-- Theme Js -->  
  <script src="static/js/jquery.nav.js"></script>
  <script src="static/js/custom.js"></script>
  <script src="static/js/home.js"></script><!-- Only For Home page -->
  <!-- End -->
</body>
<!-- ========== End of Body ========== -->
</html>
