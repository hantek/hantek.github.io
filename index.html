<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ZHOUHAN LIN</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
    <link rel="stylesheet" href="./index.css">
</head>

<body>
    <div>
        <!-- This is header -->
        <header class="home-header">
            <div class="header-content row d-flex flex-wrap align-items-center justify-content-between">
                <div class="header-logo col-sm-4">ZHOUHAN LIN</div>
                <ul class="col-sm-8 col-md-auto m-0 d-flex flex-wrap align-items-center justify-content-center justify-content-md-between list-unstyled">

                    <li class="px-4 mx-16">
                        <div class="navbar-header">
                            <a class="navbar-brand" href="#bio">Bio</a>
                        </div>
                    </li>
                    <li class="px-4 mx-16">
                        <div class="navbar-header">
                            <a class="navbar-brand" href="#research">Research</a>
                        </div>
                    </li>
                    <li class="px-4 mx-16">
                        <div class="navbar-header">
                            <a class="navbar-brand" href="#teaching">Teaching</a>
                        </div>
                    </li>
                    <li class="px-4 mx-16">
                        <div class="navbar-header">
                            <a class="navbar-brand" href="#news">News</a>
                        </div>
                    </li>
                    <li class="px-4 mx-16">
                        <div class="navbar-header">
                            <a class="navbar-brand" href="#publications">Publications</a>
                        </div>
                    </li>
                    <!-- 在这里新增header navigation，格式如下： -->
                    <!-- <li class="px-4 mx-16">
                        <div class="navbar-header">
                            <a class="navbar-brand" href="#publications">Publications</a>
                        </div>
                    </li> -->
                </ul>
            </div>
        </header>
        <section class="section-container">
            <section id="head" class="section-item">
                <div class="row">
                    <div class="col-xs-12 col-sm-4">
                        <img src="assets/img/coverphoto.jpg" alt="" srcset="" width="80%">
                    </div>
                    <div class="col-xs-12 col-sm-8">
                        <h2 style="margin-bottom: 24px;">Zhouhan Lin (林洲汉)</h2>
                        <div>
                            <span style="font-weight: 500; font-size: 24px;">Associate Professor</span>
                        </div>
                        <div>
                            <span style="font-weight: 500;">Deputy Director of <a href="https://jhc.sjtu.edu.cn/">John Hopcroft Center of Computer Science (JHC)</a></span>
                        </div>
                        <div>
                            <span style="font-weight: 500;"><a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a></span>
                        </div>
                        <div style="display: flex;">
                            <div style="margin-right: 4px;">
                                <span style="font-weight: 500;">E-mail : 
                            </div>
                            <div>
                                <span> lastname[dot]firstname[the simbol]gmail.com <span style="font-weight: 500;">or</span></span>
                                <p>[github name][the simbol][university abbreviation].edu.cn</p>
                            </div>
                        </div>

                        <p>
                            <span style="font-weight: 500;">Office :</span> Room 815B, Neo Bay #1 Building South Tower, No. 951 Jianchuan Road.
                        </p>
                        <p class="link-block">
                            <a href="https://scholar.google.com/citations?user=LNZ4efwAAAAJ&hl=en" target="_blank">
                                <img src="./assets//gscholar.png" alt="" srcset="" style="width: 32px;">
                            </a>
                            <a href="https://www.semanticscholar.org/author/Zhouhan-Lin/3146592" target="_blank">
                                <img src="./assets/sscholar.png" alt="" srcset="">
                            </a>
                            <a href="https://github.com/hantek" target="_blank">
                                <img src="./assets/github.svg" alt="" srcset="">
                            </a>
                            <a href="https://www.zhihu.com/people/linzhouhan" target="_blank">
                                <img src="./assets/zhihu.svg" alt="" srcset="">
                            </a>
                            <a href="https://www.facebook.com/zhouhan.lin.9/" target="_blank">
                                <img src="./assets/facebook.svg" alt="" srcset="" style="width: 32px;">
                            </a>
                            <a href="https://twitter.com/zhouhan_lin" target="_blank">
                                <img src="./assets/twitter.svg" alt="" srcset="">
                            </a>
                            <a href="https://ca.linkedin.com/in/zhouhan-lin-34b98975" target="_blank">
                                <img src="./assets/linkedin.svg" alt="" srcset="">
                            </a>
                        </p>
                    </div>
                </div>
            </section>

            <!--This is Bio -->
            <!-- 这里的id="bio"，需要与header中的href="#bio"对应，用来点击滑动定位 -->
            <section id="bio" class="section-item">
                <h3 style="margin: 0;">
                    Bio
                </h3>
                <p>
                    I am an associate professor at the <a href="https://sai.sjtu.edu.cn/">School of Artificial Intellengence</a> and the 
                    <a href="https://jhc.sjtu.edu.cn/">John Hopcroft Center of Computer Science</a> 
                    at <a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University (SJTU)</a>.
                    I am leading the <a href="https://github.com/LUMIA-Group">Language Understanding and Machine Intelligence Algorithms (LUMIA) Lab</a>.
                    Before joining SJTU, I was a visiting scientist at <a href="https://ai.facebook.com/">Facebook AI Research (FAIR)</a> in Menlo Park, CA, 
                    working with <a href="https://michaelauli.github.io/">Michael Auli</a>. 
                    I received my Ph.D. in Computer Science from the <a href="https://mila.quebec/en/">Mila lab</a> 
                    in the <a href="https://www.umontreal.ca/en/"> University of Montreal</a> in 2019, 
                    where I was fortunately supervised by <a href="https://yoshuabengio.org/">Yoshua Bengio</a>. 
                    During my Ph.D., I've been interning at
                    <a href="https://research.google/teams/language/">Google AI Language team</a> in the New York City, and at <a href="https://www.ibm.com/watson">IBM Watson</a> 
                    with <a href="https://scholar.google.com/citations?user=h3Nsz6YAAAAJ&hl=en">Bowen Zhou</a> and 
                    <a href="https://sites.google.com/site/moyunlp/">Mo Yu</a> in Yorktown Height, NY. I also worked as a part-time student researcher at 
                    <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-montreal/">Microsoft Research</a>
                    with <a href="https://www.microsoft.com/en-us/research/people/alsordon/">Alessandro Sordoni</a> and 
                    <a href="https://scholar.google.ca/citations?hl=en">Adam Trischler</a> in Montreal.
                    Prior to Mila, I received my B.Sc. (2012) and M.Sc. (2014) degrees from 
                    <a href="http://en.hit.edu.cn/">Harbin Institute of Technology</a>. For more information, you can find my CV <a href="assets/CV_Zhouhan_Lin.pdf">here</a>. 
                </p>
                <p>
                    I am actively looking for highly motivated undergrads, interns, and <span style="font-weight: 500;">prospective Master's (2027) or Ph.D. (2027) students</span> to work with me. 
                    If you are interested in my research topics, please kindly drop me an email, preferably the @sjtu.edu.cn address.
                    <span style="font-weight: 500;">Unfortunately, I have no more Ph.D. nor Master positions available for the year 2026.</span>
                </p>

            </section>

            <section id="research" class="section-item">
                <h3 style="margin: 0;">
                    Research
                </h3>
                <p>
                    My core research interest is <span style="font-weight: 500;">to explore and develop machine intelligence capable of acquiring, forming, reasoning, and interacting with abstract concepts</span> from large amounts of data,
                    especially through self-supervised learning. 
                    Almost all of my research efforts are centered around this goal, touching on a diverse range of topics such as attention mechanisms, language modeling, dialog systems, automated summarization, grammar induction, 
                    graph neural networks, code generation, etc. A list of topics that I am interested in at the moment are:
                </p>
                <ul class="row">
                    <li> New neural network architectures beyond decoder-only Transformers, such as learning multi-scale representations, external memory, etc. </li>
                    <li> New pretraining tasks beyond next-token-prediction, such as retriever immitation, next-context-prediction, etc. </li>
                    <li> Long sequence modeling and efficient models, such as efficient attention mechanisms, KV compression, etc.</li>
                    <!-- 在这里新建一条新的news，格式如下 -->
                    <!-- <li>新内容</li> -->
                </ul>
            </section>

            <section id="teaching" class="section-item">
                <h3 style="margin: 0;">
                    Teaching
                </h3>
                <ul class="row">
                    <li> CS-1605 Programming Practice (C++) （C++程序设计实践）</li>
                    <li> CS-3602 Natural Language Processing （自然语言处理） </li>
                </ul>
            </section>

            <!-- This is News -->
            <section id="news" class="section-item">
                <h3 style="margin: 0;">
                    News
                </h3>
                <ul class="row">
                    <li> Dec 2025: Our LUMIA lab members are going to present our Memory Decoder (<a href="https://arxiv.org/abs/2508.09874">https://arxiv.org/abs/2508.09874</a>) in NeurIPS! An external memory to LLM that allows you to plug-and-play domain knowledge! </li>
                    <li> Nov. 2025: I am serving as the organization chair of <a href="https://mlnlp.org/mlnlp2025/">MLNLP 2025</a>.  </li>
                    <li> Nov. 2025: I gave a talk at NYU Shanghai: "New Architectures for LLMs: Preliminary Explorations and Insights" (in English).  </li>
                    <li> Nov. 2025: I am organizing the workshop on "Efficient LLM architectures" in <a href="http://lmg.cipsc.org.cn/conference/lmg2025/subForum/subForum4/index.html">LMG 2025</a>. </li>
                    <li> Aug. 2025: I am serving as the workshop chair for <a href="http://cips-cl.org/static/CCL2025/cclCommittee/comChairs/index.html">CCL 2025</a>. </li>
                    <li> Aug. 2025: I gave an invited keynote talk on <a href="https://c2sml.cn/conference.html">CSML 2025</a>, "New Architectures for LLMs: Preliminary Explorations and Insights" (in Chinese).  </li>
                    <li> Dec. 2024: I gave two talks on <a href="http://lmg.cipsc.org.cn/conference/cips-lmg2024/index.html">CIPS-LMG 2024</a>. The slides can be found <a href="assets/HuRef LMG演讲.pdf">here</a> (our NeurIPS work on human-readable fingerprint) and <a href="assets/LMG讲习班-1.5h.pdf">here</a> (the efficient LLM tutorial). </li>
                    <li> Sep. 2024: Our human-readable LLM fingerprint (<a href="https://arxiv.org/abs/2312.04828">[1]</a>) and Cluster-wise Graph Transformer <a href="https://openreview.net/pdf?id=3j2nasmKkP">[2]</a>) got accepted at NeurIPS 2024, with [2] being spotlight! </li>
                    <li> Sep. 2024: Four papers (<a href="https://openreview.net/pdf?id=KpR53ZqtQ6">[1]</a><a href="https://openreview.net/pdf?id=T7fzvcq7Mf">[2]</a><a href="https://openreview.net/pdf?id=uJB6HtUAHX">[3]</a><a href="https://openreview.net/pdf?id=2shnXVWH6c">[4]</a>) are accepted
                         at EMNLP 2024! </li>
                    <li> Jan. 2024: <a href="https://openreview.net/forum?id=hv3SklibkL">One paper</a> got accepted at ICLR 2024! </li>
                    <li> Jan. 2024: Our pretrained geoscience LLMs are fully released! Papers, codes and checkpoints are available! The 30B model, named <a href="https://arxiv.org/pdf/2401.00434">GeoGalactica</a> (<a href="https://github.com/geobrain-ai/geogalactica">code&checkpoints</a>), 
                         is based on Galactica, and the 7B model, named <a href="https://dl.acm.org/doi/abs/10.1145/3616855.3635772">K2</a> (<a href="https://github.com/davendw49/k2">code&checkpoints</a>),  is based on LLaMA. </li>
                    
                    <!--These areoutdated activities, commenting out
                    <li> Sep. 2023: <a href="https://openreview.net/pdf?id=t2hEZadBBk">One paper</a> got accepted at NeurIPS 2023! </li>
                    <li> May. 2023: Two papers (<a href="https://aclanthology.org/2023.acl-long.281/">[1]</a><a href="https://aclanthology.org/2023.findings-acl.570/">[2]</a>) are accepted at ACL 2023! </li>
                    <li> Mar. 2023: <a href="https://scholar.google.com/citations?user=C-TqDNsAAAAJ">Yunchong Song</a> has got the ICLR Travel Award, congratuations! </li>
                    <li> Feb. 2023: Two papers (<a href="https://arxiv.org/abs/2302.09509">[1]</a><a href="https://arxiv.org/abs/2304.05361">[2]</a>) are accepted at ICASSP 2023! </li>
                    <li> Jan. 2023: <a href="https://openreview.net/forum?id=wKPmPBHSnT6">One paper</a> is accepted at ICLR 2023! </li>
                    <li> Oct. 2022: Three papers (<a href="https://aclanthology.org/2022.emnlp-main.211/">[1]</a><a href="https://aclanthology.org/2022.findings-emnlp.173/">[2]</a><a href="https://aclanthology.org/2022.findings-emnlp.114//">[3]</a>) are accepted
                        at EMNLP 2022! </li>
                    <li> Feb. 2022: Two papers (<a href="https://aclanthology.org/2022.acl-long.308/">[1]</a><a href="https://aclanthology.org/2022.acl-long.502/">[2]</a>) are accepted at ACL 2022! </li>
                    -->
                </ul>
            </section>


            <!-- This is publications -->
            <section id="publications" class="section-item">
                <h3 style="margin: 0;">
                    Selected Publications
                </h3>
                <p>
                    <span style="font-weight: 500;">This is a selected list of my publications. </span>
                </p>
                <p>
                    <span style="font-weight: 500;">For an up-to-date, complete list, please refer to 
                    <a href="https://scholar.google.com/citations?user=LNZ4efwAAAAJ&hl=en">my Google Scholar page</a>. </span>
                </p>
                <p>
                    <span style="font-weight: 500;">(*) indicates equal contribution. (#) indicates the corresponding author. </span>
                </p>

                <section class="research-section">
                    <!-- Memory Decoder -->
                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/memdec-intro.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models
                            </h4>
                            <p class="author">
                                Jiaqi Cao*, Jiarui Wang*, Rubin Wei, Qipeng Guo, Kai Chen, Bowen Zhou, <span style="font-weight: 500;">Zhouhan Lin#</span>
                            </p>
                            <div class="link-list">
                                <span>NeurIPS 2025 </span>
                                <span> | </span>
                                <a href="https://www.arxiv.org/pdf/2508.09874"><span>pdf</span></a>
                                <span> | </span>
                                <a href="https://github.com/LUMIA-Group/MemoryDecoder/tree/main"><span>codes</span></a>
                                <span> | </span>
                                <a href="https://huggingface.co/collections/Clover-Hill/memorydecoder"><span>checkpoints</span></a>
                                <span> | </span>
                                <a href="https://www.qbitai.com/2025/08/323458.html"><span>量子位</span></a>
                                <span> | </span>
                                <a href="https://www.youtube.com/watch?v=-oV0HpUpoGs"><span>youtube</span></a>
                                <span> | </span>
                                <a href="https://www.bilibili.com/video/BV1uGkZBUE1F"><span>bilibili</span></a>
                            </div>
                        </div>
                    </div>

                    <!-- How to Synthesize Text Data without Model Collapse? -->
                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/model_collapse.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                How to Synthesize Text Data without Model Collapse?
                            </h4>
                            <p class="author">
                                Xuekai Zhu, Daixuan Cheng, Hengli Li, Kaiyan Zhang, Ermo Hua, Xingtai Lv, Ning Ding, <span style="font-weight: 500;">Zhouhan Lin#</span>, Zilong Zheng#, Bowen Zhou#
                            </p>
                            <div class="link-list">
                                <span>ICML 2025 </span>
                                <span> | </span>
                                <a href="https://arxiv.org/abs/2412.14689"><span>pdf</span></a>
                                <span> | </span>
                                <a href="https://github.com/Xuekai-Zhu/toedit"><span>codes</span></a>
                            </div>
                        </div>
                    </div>

                    <!-- research 1 -->
                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/gpn.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                Graph Parsing Networks
                            </h4>
                            <p class="author">
                                Yunchong Song, Siyuan Huang, Xinbing Wang, Chenghu Zhou, <span style="font-weight: 500;">Zhouhan Lin#</span>
                            </p>
                            <div class="link-list">
                                <span>ICLR 2024 (Poster) </span>
                                <span> | </span>
                                <a href="https://arxiv.org/pdf/2402.14393"><span>pdf</span></a>
                                <span> | </span>
                                <a href="https://github.com/LUMIA-Group/GraphParsingNetworks"><span>codes</span></a>
                            </div>
                    </div>
                    
                    <!-- research 1 -->
                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/muteswap.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                Visual-informed Silent Video Identity Conversion
                            </h4>
                            <p class="author">
                                Yifan Liu, Yu Fang, <span style="font-weight: 500;">Zhouhan Lin#</span>
                            </p>
                            <div class="link-list">
                                <span>ACM MultiMedia 25 </span>
                                <span> | </span>
                                <a href="https://www.arxiv.org/pdf/2507.00498"><span>pdf</span></a>
                                <span> | </span>
                                <a href="https://pussycat0700.github.io/MuteSwap-Demo/"><span>demo page</span></a>
                                <span> | </span>
                                <a href="https://dl.acm.org/doi/suppl/10.1145/3746027.3755678/suppl_file/mfp5195-promo-video.mp4"><span>video</span></a>
                                <span> | </span>
                                <a href="https://github.com/PussyCat0700/DiVISe"><span>codes</span></a>
                            </div>
                    </div>

                    <!-- research 1 -->
                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/AdaptiveStep.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence
                            </h4>
                            <p class="author">
                                Yuliang Liu*, Junjie Lu*, Chaofeng Qu, Zhaoling Chen, Zefan Cai, Jason Klein Liu, Chonghan Liu, Yunhui Xia, Li Zhao, Jiang Bian, Chuheng Zhang, Wei Shen, <span style="font-weight: 500;">Zhouhan Lin#</span>
                            </p>
                            <div class="link-list">
                                <span>ICML 25 </span>
                                <span> | </span>
                                <a href="https://arxiv.org/abs/2502.13943"><span>pdf</span></a>
                                <span> | </span>
                                <a href="https://github.com/Lux0926/ASPRM"><span>codes</span></a>
                                <span> | </span>
                                <a href="https://zhuanlan.zhihu.com/p/27303531524"><span>Zhihu(知乎)</span></a>
                                <span> | </span>
                                <a href="https://www.bilibili.com/video/BV1EutEzTEgR/?share_source=copy_web&vd_source=4b4b2a58784294287ab1b1036e0dd3aa"><span>bilibili</span></a>
                                <span> | </span>
                                <a href="https://mp.weixin.qq.com/s/LNZvhAFGJkZ_J2MHWmIz2w"><span>微软亚洲研究院</span></a>
                            </div>
                    </div>

                    <!-- research 1 -->
                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/anchor.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                Training LLMs to be Better Text Embedders through Bidirectional Reconstruction
                            </h4>
                            <p class="author">
                                Chang Su, Dengliang Shi, Siyuan Huang, Jintao Du, Changhua Meng, Yu Cheng, Weiqiang Wang, <span style="font-weight: 500;">Zhouhan Lin#</span>
                            </p>
                            <div class="link-list">
                                <span>EMNLP 2025 </span>
                                <span> | </span>
                                <a href="https://aclanthology.org/2025.emnlp-main.216.pdf"><span>pdf</span></a>
                                <span> | </span>
                                <a href="https://github.com/LUMIA-Group/Anchor-Embedding"><span>codes</span></a>
                            </div>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/reranker.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                Gumbel Reranking: Differentiable End-to-End Reranker Optimization
                            </h4>
                            <p class="author">
                                Siyuan Huang, Zhiyuan Ma, Jintao Du, Changhua Meng, Weiqiang Wang, Jingwen Leng, Minyi Guo, <span style="font-weight: 500;">Zhouhan Lin#</span>
                            </p>
                            <div class="link-list">
                                <span>ACL 2025 (Main Conference) </span>
                                <span> | </span>
                                <a href="https://arxiv.org/abs/2502.11116"><span>pdf</span></a>
                                <span> | </span>
                                <a href="https://github.com/LUMIA-Group/Gumbel-Reranking"><span>codes</span></a>
                            </div>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/cluster_gt.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                Cluster-wise Graph Transformer with Dual-granularity Kernelized Attention
                            </h4>
                            <p class="author">
                                Siyuan Huang, Yunchong Song, Jiayue Zhou, <span style="font-weight: 500;">Zhouhan Lin#</span>
                            </p>
                            <div class="link-list">
                                <span>NeurIPS 2024 (Spotlight) </span>
                                <span> | </span>
                                <a href="https://arxiv.org/abs/2410.06746"><span>pdf</span></a>
                                <span> | </span>
                                <a href="https://github.com/LUMIA-Group/Cluster-wise-Graph-Transformer"><span>codes</span></a>
                            </div>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/subtree_attn.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                Tailoring Self-Attention for Graph via Rooted Subtrees
                            </h4>
                            <p class="author">
                                Siyuan Huang, Yunchong Song, Jiayue Zhou, <span style="font-weight: 500;">Zhouhan Lin#</span>
                            </p>
                            <div class="link-list">
                                <span>NeurIPS 2023 </span>
                                <span> | </span>
                                <a href="https://arxiv.org/abs/2310.05296"><span>pdf</span></a>
                                <span> | </span>
                                <a href="https://github.com/LUMIA-Group/SubTree-Attention"><span>codes</span></a>
                            </div>
                        </div>
                    </div>

                    <!-- research 1 -->
                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/orderedgnn.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                Ordered GNN: Ordering Message Passing to Deal with Heterophily and Over-smoothing
                            </h4>
                            <p class="author">
                                Yunchong Song, Chenghu Zhou, Xinbing Wang, <span style="font-weight: 500;">Zhouhan Lin#</span>
                            </p>
                            <div class="link-list">
                                <span>ICLR 2023 </span>
                                <span> | </span>
                                <a href="https://arxiv.org/pdf/2302.01524.pdf"><span>pdf</span></a>
                                <span> | </span>
                                <a href="https://github.com/LUMIA-Group/OrderedGNN"><span>codes</span></a>
                            </div>
                        </div>
                    </div>

                    <!-- research 1 -->
                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/huref.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                HuRef: HUman-REadable Fingerprint for Large Language Models
                            </h4>
                            <p class="author">
                                Boyi Zeng, Lizheng Wang, Yuncong Hu, Yi Xu, Chenghu Zhou, Xinbing Wang, Yu Yu, <span style="font-weight: 500;">Zhouhan Lin#</span>
                            </p>
                            <div class="link-list">
                                <span>NeurIPS 2024 (Poster) </span>
                                <span> | </span>
                                <a href="https://arxiv.org/abs/2312.04828"><span>pdf</span></a>
                                <span> | </span>
                                <a href="https://github.com/LUMIA-Group/HuRef"><span>codes</span></a>
                                <span> | </span>
                                <a href="https://mp.weixin.qq.com/s/wy2HKsG-HRk8p6pe5pW87A"><span>blog</span></a>
                            </div>
                    <!-- research 1 -->
                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/rasat.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                RASAT: Integrating Relational Structures into Pretrained Seq2Seq Model for Text-to-SQL
                            </h4>
                            <p class="author">
                                Jiexing Qi, Jingyao Tang, Ziwei He, Xiangpeng Wan, Yu Cheng, Chenghu Zhou, Xinbing Wang, Quanshi Zhang, <span style="font-weight: 500;">Zhouhan Lin#</span>
                            </p>
                            <div class="link-list">
                                <span>EMNLP 2022 </span>
                                <span> | </span>
                                <a href="https://arxiv.org/pdf/2205.06983.pdf"><span>pdf</span></a>
                                <span> | </span>
                                <a href="https://github.com/LUMIA-Group/rasat"><span>codes</span></a>
                            </div>
                        </div>
                    </div>

                    <!-- research 1 -->
                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/distanceparser.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                Straight to the Tree: Constituency Parsing with Neural Syntactic Distance
                            </h4>
                            <p class="author">
                                Yikang Shen*, <span style="font-weight: 500;">Zhouhan Lin</span>*, Athul Paul Jacob, Alessandro Sordoni, Aaron Courville, Yoshua Bengio
                            </p>
                            <div class="link-list">
                                <span>ACL 2018 </span>
                                <span> | </span>
                                <a href="https://arxiv.org/pdf/1806.04168.pdf"><span>pdf</span></a>
                                <span> | </span>
                                <a href="http://"><span>slides</span></a>
                                <span> | </span>
                                <a href="https://github.com/hantek/distance-parser"><span>codes</span></a>
                            </div>
                        </div>
                    </div>

                    <!-- research 3 -->
                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/tree.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                Neural Language Modeling by Jointly Learning Syntax and Lexicon
                            </h4>
                            <p class="author">
                                Yikang Shen, <span style="font-weight: 500;">Zhouhan Lin</span>, Chin-Wei Huang, Aaron Courville
                            </p>
                            <div class="link-list">
                                <span>ICLR 2018</span>
                                <span> | </span>
                                <a href="https://arxiv.org/pdf/1711.02013.pdf"><span>pdf</span></a>
                                <span> | </span>
                                <a href="http://https://github.com/yikangshen/PRPN"><span>codes</span></a>
                                <!-- <span> | </span> -->
                                <!-- <a href=""><span>poster</span></a> -->
                            </div>
                        </div>
                    </div>
                    <!-- research 4 -->
                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/semlp.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                A structured self-attentive Sentence Embedding
                            </h4>
                            <p class="author">
                                <span style="font-weight: 500;">Zhouhan Lin</span>, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou and Yoshua Bengio
                            </p>
                            <div class="link-list">
                                <span class="time">ICLR 2017</span>
                                <span> | </span>
                                <a href="https://arxiv.org/pdf/1703.03130.pdf"><span>pdf</span></a>
                                <span> | </span>
                                <a href="https://github.com/hantek/SelfAttentiveSentEmbed"><span>codes</span></a>
                                <!-- <span> | </span> -->
                                <!-- <a href=""><span>poster</span></a> -->
                            </div>
                        </div>
                    </div>

                    <!-- research 5 -->
                    <div class="row">
                        <div class="col-xs-12 col-sm-4">
                            <img width="100%" src="./assets/research/exp_quant.png" alt="" srcset="">
                        </div>
                        <div class="col-xs-12 col-sm-8">
                            <h4>
                                Neural networks with few multiplications
                            </h4>
                            <p class="author">
                                <span style="font-weight: 500;">Zhouhan Lin</span>, Matthieu Courbariaux, Roland Memisevic, and Yoshua Bengio
                            </p>
                            <div class="link-list">
                                <span class="time">ICLR 2016 (oral)</span>
                                <span> | </span>
                                <a href="https://arxiv.org/pdf/1510.03009.pdf"><span>pdf</span></a>
                                <span> | </span>
                                <a href="https://github.com/hantek/BinaryConnect"><span>codes</span></a>
                                <!-- <span> | </span> -->
                                <!-- <a href=""><span>poster</span></a> -->
                            </div>
                        </div>
                    </div>

                    <!-- 在这里新建一个新的research，可复制一段research代码，从class=row开始, 格式如下 -->
                    <!-- <div class="row">……</div> -->
                </section>

            </section>

        </section>
    </div>
    <!-- jQuery文件。务必在bootstrap.min.js 之前引入 -->
    <script src="https://cdn.staticfile.org/jquery/2.1.1/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
    <script src="./index.js"></script>
</body>

</html>
